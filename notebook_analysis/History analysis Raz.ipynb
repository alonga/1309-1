{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\meira\\anaconda3\\lib\\site-packages (3.5)\n",
      "Requirement already satisfied: click in c:\\users\\meira\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\meira\\anaconda3\\lib\\site-packages (from nltk) (0.17.0)\n",
      "Requirement already satisfied: regex in c:\\users\\meira\\anaconda3\\lib\\site-packages (from nltk) (2020.10.15)\n",
      "Requirement already satisfied: tqdm in c:\\users\\meira\\anaconda3\\lib\\site-packages (from nltk) (4.50.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from nltk.corpus import brown\n",
    "from urllib.parse import urlparse\n",
    "import nltk\n",
    "import re\n",
    "import os\n",
    "PATH=os.getcwd()\n",
    "#nltk.download('brown')\n",
    "import string\n",
    "def preprocess(text):\n",
    "    text = text.lower() \n",
    "    text=text.strip()  \n",
    "    text=re.compile('<.*?>').sub('', text) \n",
    "    text = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', text)  \n",
    "    text = re.sub('\\s+', ' ', text)  \n",
    "    text = re.sub(r'\\[[0-9]*\\]',' ',text) \n",
    "    text=re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "    text = re.sub(r'\\d',' ',text) \n",
    "    text = re.sub(r'\\s+',' ',text) \n",
    "    return text\n",
    "def get_website(x):\n",
    "    x = urlparse(x).netloc\n",
    "    return x\n",
    "def filter_tags(taglist, history):\n",
    "    '''\n",
    "    Creates a list (tags_in) of the words in the original list that are also the full_data column.\n",
    "    drops words from list that are also in corpus. drops words with len < \n",
    "    '''\n",
    "    tags_in = []\n",
    "\n",
    "    for tag in taglist:\n",
    "        count = history[\"clean_full_data\"].str.contains(tag, regex=False).sum()\n",
    "        if (count>0) :\n",
    "            tags_in.append(tag)\n",
    "\n",
    "    return tags_in\n",
    "## Utils\n",
    "\n",
    "# get decrption \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import xml.etree.ElementTree as et\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "url = 'https://reactjs.org/'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text)\n",
    "\n",
    "metas = soup.find_all('meta')\n",
    "\n",
    "ls= [ meta.attrs['content'] for meta in metas if 'name' in meta.attrs and meta.attrs['name'] == 'description' ]\n",
    "\n",
    "def get_q(x):\n",
    "    x = urlparse(x).query\n",
    "    return x\n",
    "def get_fragment(x):\n",
    "    x = urlparse(x).fragment\n",
    "    return x\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import xml.etree.ElementTree as et\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "CUT_OFF= 1800\n",
    "\n",
    "def parse_XML(xml_file, df_cols): \n",
    "    \"\"\"Parse the input XML file and store the result in a pandas \n",
    "    DataFrame with the given columns. \n",
    "    \n",
    "    The first element of df_cols is supposed to be the identifier \n",
    "    variable, which is an attribute of each node element in the \n",
    "    XML data; other features will be parsed from the text content \n",
    "    of each sub-element. \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    xtree = et.parse(xml_file)\n",
    "    xroot = xtree.getroot()\n",
    "    rows = []\n",
    "    \n",
    "    for node in xroot: \n",
    "        res = []\n",
    "        res.append(node.attrib.get(df_cols[0]))\n",
    "        for el in df_cols[1:]: \n",
    "            if node is not None and node.find(el) is not None:\n",
    "                res.append(node.find(el).text)\n",
    "            else: \n",
    "                res.append(None)\n",
    "        rows.append({df_cols[i]: res[i] \n",
    "                     for i, _ in enumerate(df_cols)})\n",
    "    \n",
    "    out_df = pd.DataFrame(rows, columns=df_cols)\n",
    "        \n",
    "    return out_df\n",
    "\n",
    "def xml_to_list (xml_file):\n",
    "    '''\n",
    "    takes file location 'xml_file' and gives a list of the values in the xml_file.\n",
    "    '''\n",
    "    df=parse_XML(xml_file, [\"TagName\"])\n",
    "    df['TagName']=\" \"+df['TagName']+\" \"\n",
    "    df['TagName'].replace(\"-\",\" \",inplace=True,regex=True)\n",
    "    tag_ls=(df['TagName']).tolist()\n",
    "    tags_to_drop = [' facebook ', ' twitter ', ' gmail ',\n",
    "            ' google forms ', ' profile ', ' inbox ', \n",
    "            ' email ', ' drive ', ' spotify ', \n",
    "            ' search ', ' whatsapp ', ' join ', \n",
    "            ' view ', ' agenda ', ' google docs ', \n",
    "            ' free ', ' add ', ' release ', \n",
    "            ' seconds ', ' linkedin ', 'xiaomi'\n",
    "            ' global ', ' launch ', \n",
    "            ' post ', ' using ', ' this ']\n",
    "\n",
    "    for tag in tag_ls:\n",
    "        if (len(tag) < 5) or tag in tags_to_drop:\n",
    "            tag_ls.remove(tag)\n",
    "    \n",
    "\n",
    "    return tag_ls\n",
    "\n",
    "def get_website(x):\n",
    "    x = urlparse(x).netloc\n",
    "    return x\n",
    "\n",
    "def create_history(csv_file):\n",
    "    '''\n",
    "    reads csv file into DF 'history', and:\n",
    "    1. parse dates\n",
    "    3. creates 'website' column\n",
    "    2. creates 'full_data' column - title + url in lowercase\n",
    "    3. removes special charecters from full_data\n",
    "    \n",
    "    csv_file should be entered with r'file.csv' (r and '')\n",
    "\n",
    "    '''\n",
    "    history = pd.read_csv(csv_file, parse_dates=[['date', 'time']])\n",
    "    history['website'] = history.url.apply(get_website)\n",
    "    history['full_data'] = (history['url']+\" \"+history['title']+\" \").str.lower()\n",
    "    history['full_data'] = (history['full_data']).str.replace(r'[^\\w\\s]+', ' ', regex=True)\n",
    "        \n",
    "    return history\n",
    "\n",
    "def time_spent (x):\n",
    "    '''\n",
    "    creates column with time spent in website session (in seconds)\n",
    "    if the time spent is over 30 min (1800 seconds = cut off), the time spent column will display the median for the website\n",
    "    '''\n",
    "    #time spent in website (in seconds)\n",
    "    history['end_time'] = history.date_time.shift(1)\n",
    "    history['time_spent'] = (history.end_time - history.date_time).dt.seconds\n",
    "    #create Nan values:\n",
    "    history['time_spent'] = history.time_spent.apply(lambda x: np.nan if x >= CUT_OFF else x)\n",
    "    #NaN values to website median\n",
    "    grouped = history.groupby(['website']).time_spent\n",
    "    history['time_spent'] = grouped.transform(lambda x: x.fillna(x.median()))\n",
    "    history.drop('end_time', axis='columns')\n",
    "\n",
    "def filter_tags(taglist, corpus, history):\n",
    "    '''\n",
    "    Creates a list (tags_in) of the words in the original list that are also the full_data column.\n",
    "    drops words from list that are also in corpus. drops words with len < \n",
    "    '''\n",
    "    tags_in = []\n",
    "    word_list = corpus.words()\n",
    "\n",
    "    for tag in tag_ls:\n",
    "        count = history[\"clean_full_data\"].str.contains(tag, regex=False).sum()\n",
    "        if (count>0) and (tag.replace(' ','') not in word_list):\n",
    "            tags_in.append(tag)\n",
    "\n",
    "    return tags_in\n",
    "\n",
    "def is_study (tags, urls):\n",
    "    '''\n",
    "    returns a list 'match_tags' of tags that appear in each row in history, by order.\n",
    "    if no tag is found, the value is set to 'irrelevent'.\n",
    "    '''    \n",
    "    match_tags = [\"irrelevent\"] * len(urls)\n",
    "    \n",
    "    for tag in tags:\n",
    "        # compile regex per tag (here so we dont do this again in the nested loop)\n",
    "        match_string = re.compile(f\".*{tag}.*\")\n",
    "        for i,url in enumerate(urls):\n",
    "            if re.fullmatch(match_string, str(url)):\n",
    "                if match_tags[i] == \"irrelevent\":\n",
    "                    match_tags[i] = tag\n",
    "                else:\n",
    "                    match_tags[i] += f\", {tag}\"        \n",
    "        history[tag] = history['full_data'].str.contains(tag, regex=False)\n",
    "\n",
    "    return match_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from nltk.corpus import brown\n",
    "from urllib.parse import urlparse\n",
    "import nltk\n",
    "import re\n",
    "import os\n",
    "PATH=os.getcwd()\n",
    "\n",
    "# Opening JSON file and read file\n",
    "f = open(os.path.join(PATH,r\"BrowserHistory.json\"))\n",
    "data = json.load(f)\n",
    "f.close()\n",
    "history=pd.json_normalize(data['Browser History'])\n",
    "\n",
    "tags=pd.read_excel(os.path.join(PATH,r\"tags.xlsx\"))\n",
    "word_list = brown.words()\n",
    "tags['rank']=tags.index\n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "\n",
    "\n",
    "history['time']=pd.to_datetime(history['time_usec'], unit='us')\n",
    "history['website']=history['url'].apply(get_website)\n",
    "history[\"new_url\"]= history.apply(lambda x: x['url'].replace(r\"https://\"+x['website']+r\"/\", \"\"), axis=1)\n",
    "history['full_data'] = (history['new_url']+\" \"+history['title']+\" \").str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "history['clean_text'] = history['full_data'].apply(lambda x: preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favicon_url</th>\n",
       "      <th>page_transition</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>client_id</th>\n",
       "      <th>time_usec</th>\n",
       "      <th>time</th>\n",
       "      <th>new_url</th>\n",
       "      <th>full_data</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>website</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>m.facebook.com</th>\n",
       "      <td>4</td>\n",
       "      <td>167</td>\n",
       "      <td>167</td>\n",
       "      <td>167</td>\n",
       "      <td>167</td>\n",
       "      <td>167</td>\n",
       "      <td>167</td>\n",
       "      <td>167</td>\n",
       "      <td>167</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discord.com</th>\n",
       "      <td>28</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>webhook.site</th>\n",
       "      <td>159</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analytics.google.com</th>\n",
       "      <td>114</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>www.linkedin.com</th>\n",
       "      <td>144</td>\n",
       "      <td>208</td>\n",
       "      <td>208</td>\n",
       "      <td>208</td>\n",
       "      <td>208</td>\n",
       "      <td>208</td>\n",
       "      <td>208</td>\n",
       "      <td>208</td>\n",
       "      <td>208</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>localhost:8888</th>\n",
       "      <td>213</td>\n",
       "      <td>214</td>\n",
       "      <td>214</td>\n",
       "      <td>214</td>\n",
       "      <td>214</td>\n",
       "      <td>214</td>\n",
       "      <td>214</td>\n",
       "      <td>214</td>\n",
       "      <td>214</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m.imdb.com</th>\n",
       "      <td>0</td>\n",
       "      <td>219</td>\n",
       "      <td>219</td>\n",
       "      <td>219</td>\n",
       "      <td>219</td>\n",
       "      <td>219</td>\n",
       "      <td>219</td>\n",
       "      <td>219</td>\n",
       "      <td>219</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>www.tase.co.il</th>\n",
       "      <td>217</td>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>www.bizportal.co.il</th>\n",
       "      <td>212</td>\n",
       "      <td>231</td>\n",
       "      <td>231</td>\n",
       "      <td>231</td>\n",
       "      <td>231</td>\n",
       "      <td>231</td>\n",
       "      <td>231</td>\n",
       "      <td>231</td>\n",
       "      <td>231</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>web.whatsapp.com</th>\n",
       "      <td>247</td>\n",
       "      <td>247</td>\n",
       "      <td>247</td>\n",
       "      <td>247</td>\n",
       "      <td>247</td>\n",
       "      <td>247</td>\n",
       "      <td>247</td>\n",
       "      <td>247</td>\n",
       "      <td>247</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drive.google.com</th>\n",
       "      <td>256</td>\n",
       "      <td>260</td>\n",
       "      <td>260</td>\n",
       "      <td>260</td>\n",
       "      <td>260</td>\n",
       "      <td>260</td>\n",
       "      <td>260</td>\n",
       "      <td>260</td>\n",
       "      <td>260</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>www.zap.co.il</th>\n",
       "      <td>18</td>\n",
       "      <td>306</td>\n",
       "      <td>306</td>\n",
       "      <td>306</td>\n",
       "      <td>306</td>\n",
       "      <td>306</td>\n",
       "      <td>306</td>\n",
       "      <td>306</td>\n",
       "      <td>306</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stackoverflow.com</th>\n",
       "      <td>293</td>\n",
       "      <td>369</td>\n",
       "      <td>369</td>\n",
       "      <td>369</td>\n",
       "      <td>369</td>\n",
       "      <td>369</td>\n",
       "      <td>369</td>\n",
       "      <td>369</td>\n",
       "      <td>369</td>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maya.tase.co.il</th>\n",
       "      <td>421</td>\n",
       "      <td>439</td>\n",
       "      <td>439</td>\n",
       "      <td>439</td>\n",
       "      <td>439</td>\n",
       "      <td>439</td>\n",
       "      <td>439</td>\n",
       "      <td>439</td>\n",
       "      <td>439</td>\n",
       "      <td>439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>docs.google.com</th>\n",
       "      <td>416</td>\n",
       "      <td>481</td>\n",
       "      <td>481</td>\n",
       "      <td>481</td>\n",
       "      <td>481</td>\n",
       "      <td>481</td>\n",
       "      <td>481</td>\n",
       "      <td>481</td>\n",
       "      <td>481</td>\n",
       "      <td>481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>github.com</th>\n",
       "      <td>227</td>\n",
       "      <td>598</td>\n",
       "      <td>598</td>\n",
       "      <td>598</td>\n",
       "      <td>598</td>\n",
       "      <td>598</td>\n",
       "      <td>598</td>\n",
       "      <td>598</td>\n",
       "      <td>598</td>\n",
       "      <td>598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tovtech.org</th>\n",
       "      <td>431</td>\n",
       "      <td>611</td>\n",
       "      <td>611</td>\n",
       "      <td>611</td>\n",
       "      <td>611</td>\n",
       "      <td>611</td>\n",
       "      <td>611</td>\n",
       "      <td>611</td>\n",
       "      <td>611</td>\n",
       "      <td>611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>newtab</th>\n",
       "      <td>0</td>\n",
       "      <td>785</td>\n",
       "      <td>785</td>\n",
       "      <td>785</td>\n",
       "      <td>785</td>\n",
       "      <td>785</td>\n",
       "      <td>785</td>\n",
       "      <td>785</td>\n",
       "      <td>785</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mail.google.com</th>\n",
       "      <td>1049</td>\n",
       "      <td>1057</td>\n",
       "      <td>1057</td>\n",
       "      <td>1057</td>\n",
       "      <td>1057</td>\n",
       "      <td>1057</td>\n",
       "      <td>1057</td>\n",
       "      <td>1057</td>\n",
       "      <td>1057</td>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>www.google.com</th>\n",
       "      <td>1792</td>\n",
       "      <td>2463</td>\n",
       "      <td>2463</td>\n",
       "      <td>2463</td>\n",
       "      <td>2463</td>\n",
       "      <td>2463</td>\n",
       "      <td>2463</td>\n",
       "      <td>2463</td>\n",
       "      <td>2463</td>\n",
       "      <td>2463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      favicon_url  page_transition  title   url  client_id  \\\n",
       "website                                                                      \n",
       "m.facebook.com                  4              167    167   167        167   \n",
       "discord.com                    28              172    172   172        172   \n",
       "webhook.site                  159              193    193   193        193   \n",
       "analytics.google.com          114              206    206   206        206   \n",
       "www.linkedin.com              144              208    208   208        208   \n",
       "localhost:8888                213              214    214   214        214   \n",
       "m.imdb.com                      0              219    219   219        219   \n",
       "www.tase.co.il                217              227    227   227        227   \n",
       "www.bizportal.co.il           212              231    231   231        231   \n",
       "web.whatsapp.com              247              247    247   247        247   \n",
       "drive.google.com              256              260    260   260        260   \n",
       "www.zap.co.il                  18              306    306   306        306   \n",
       "stackoverflow.com             293              369    369   369        369   \n",
       "maya.tase.co.il               421              439    439   439        439   \n",
       "docs.google.com               416              481    481   481        481   \n",
       "github.com                    227              598    598   598        598   \n",
       "tovtech.org                   431              611    611   611        611   \n",
       "newtab                          0              785    785   785        785   \n",
       "mail.google.com              1049             1057   1057  1057       1057   \n",
       "www.google.com               1792             2463   2463  2463       2463   \n",
       "\n",
       "                      time_usec  time  new_url  full_data  clean_text  \n",
       "website                                                                \n",
       "m.facebook.com              167   167      167        167         167  \n",
       "discord.com                 172   172      172        172         172  \n",
       "webhook.site                193   193      193        193         193  \n",
       "analytics.google.com        206   206      206        206         206  \n",
       "www.linkedin.com            208   208      208        208         208  \n",
       "localhost:8888              214   214      214        214         214  \n",
       "m.imdb.com                  219   219      219        219         219  \n",
       "www.tase.co.il              227   227      227        227         227  \n",
       "www.bizportal.co.il         231   231      231        231         231  \n",
       "web.whatsapp.com            247   247      247        247         247  \n",
       "drive.google.com            260   260      260        260         260  \n",
       "www.zap.co.il               306   306      306        306         306  \n",
       "stackoverflow.com           369   369      369        369         369  \n",
       "maya.tase.co.il             439   439      439        439         439  \n",
       "docs.google.com             481   481      481        481         481  \n",
       "github.com                  598   598      598        598         598  \n",
       "tovtech.org                 611   611      611        611         611  \n",
       "newtab                      785   785      785        785         785  \n",
       "mail.google.com            1057  1057     1057       1057        1057  \n",
       "www.google.com             2463  2463     2463       2463        2463  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.groupby(\"website\").count().sort_values(\"clean_text\").tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favicon_url</th>\n",
       "      <th>page_transition</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>client_id</th>\n",
       "      <th>time_usec</th>\n",
       "      <th>time</th>\n",
       "      <th>website</th>\n",
       "      <th>new_url</th>\n",
       "      <th>full_data</th>\n",
       "      <th>clean_full_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.thepythoncode.com/static/img/pytho...</td>\n",
       "      <td>LINK</td>\n",
       "      <td>How to Read Emails in Python - Python Code</td>\n",
       "      <td>https://www.thepythoncode.com/article/reading-...</td>\n",
       "      <td>ChCEMzICD0Hcp6qr+O44Tw==</td>\n",
       "      <td>1636729058732261</td>\n",
       "      <td>2021-11-12 14:57:38.732261</td>\n",
       "      <td>www.thepythoncode.com</td>\n",
       "      <td>article/reading-emails-in-python</td>\n",
       "      <td>article/reading-emails-in-python how to read e...</td>\n",
       "      <td>article reading emails in python how to read e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.google.com/favicon.ico</td>\n",
       "      <td>LINK</td>\n",
       "      <td>Google Takeout</td>\n",
       "      <td>https://takeout.google.com/settings/takeout?pli=1</td>\n",
       "      <td>ChCEMzICD0Hcp6qr+O44Tw==</td>\n",
       "      <td>1636729053479999</td>\n",
       "      <td>2021-11-12 14:57:33.479999</td>\n",
       "      <td>takeout.google.com</td>\n",
       "      <td>settings/takeout?pli=1</td>\n",
       "      <td>settings/takeout?pli=1 google takeout</td>\n",
       "      <td>settings takeout pli 1 google takeout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>LINK</td>\n",
       "      <td>Google Takeout</td>\n",
       "      <td>https://takeout.google.com/settings/takeout?pli=1</td>\n",
       "      <td>ChCEMzICD0Hcp6qr+O44Tw==</td>\n",
       "      <td>1636729051496083</td>\n",
       "      <td>2021-11-12 14:57:31.496083</td>\n",
       "      <td>takeout.google.com</td>\n",
       "      <td>settings/takeout?pli=1</td>\n",
       "      <td>settings/takeout?pli=1 google takeout</td>\n",
       "      <td>settings takeout pli 1 google takeout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.google.com/favicon.ico</td>\n",
       "      <td>GENERATED</td>\n",
       "      <td>google takeout - חיפוש ב-Google</td>\n",
       "      <td>https://www.google.com/search?q=google+takeout...</td>\n",
       "      <td>ChCEMzICD0Hcp6qr+O44Tw==</td>\n",
       "      <td>1636729048837442</td>\n",
       "      <td>2021-11-12 14:57:28.837442</td>\n",
       "      <td>www.google.com</td>\n",
       "      <td>search?q=google+takeout&amp;oq=google+takeout&amp;aqs=...</td>\n",
       "      <td>search?q=google+takeout&amp;oq=google+takeout&amp;aqs=...</td>\n",
       "      <td>search q google takeout oq google takeout aqs ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.google.com/favicon.ico</td>\n",
       "      <td>GENERATED</td>\n",
       "      <td>python get latest emails in inbox - חיפוש ב-Go...</td>\n",
       "      <td>https://www.google.com/search?q=python+get+lat...</td>\n",
       "      <td>ChCEMzICD0Hcp6qr+O44Tw==</td>\n",
       "      <td>1636729042414008</td>\n",
       "      <td>2021-11-12 14:57:22.414008</td>\n",
       "      <td>www.google.com</td>\n",
       "      <td>search?q=python+get+latest+mails+in+inbox&amp;oq=p...</td>\n",
       "      <td>search?q=python+get+latest+mails+in+inbox&amp;oq=p...</td>\n",
       "      <td>search q python get latest mails in inbox oq p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20950</th>\n",
       "      <td>NaN</td>\n",
       "      <td>LINK</td>\n",
       "      <td>LinkedIn Profile Scraper | Phantombuster</td>\n",
       "      <td>https://phantombuster.com/automations/linkedin...</td>\n",
       "      <td>dRUjB3pqPv09pCdNCc+N5A==</td>\n",
       "      <td>1605253150283348</td>\n",
       "      <td>2020-11-13 07:39:10.283348</td>\n",
       "      <td>phantombuster.com</td>\n",
       "      <td>automations/linkedin/3112/linkedin-profile-scr...</td>\n",
       "      <td>automations/linkedin/3112/linkedin-profile-scr...</td>\n",
       "      <td>automations linkedin 3112 linkedin profile scr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20951</th>\n",
       "      <td>NaN</td>\n",
       "      <td>RELOAD</td>\n",
       "      <td>Registration page</td>\n",
       "      <td>https://trailer.web-view.net/LandingPagesResul...</td>\n",
       "      <td>dRUjB3pqPv09pCdNCc+N5A==</td>\n",
       "      <td>1605252110781953</td>\n",
       "      <td>2020-11-13 07:21:50.781953</td>\n",
       "      <td>trailer.web-view.net</td>\n",
       "      <td>LandingPagesResult.aspx?_p=f3f2a2&amp;_u=333waaac&amp;...</td>\n",
       "      <td>landingpagesresult.aspx?_p=f3f2a2&amp;_u=333waaac&amp;...</td>\n",
       "      <td>landingpagesresult aspx p f3f2a2 u 333waaac c ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20952</th>\n",
       "      <td>NaN</td>\n",
       "      <td>LINK</td>\n",
       "      <td>מהדורה-דיגיטלית | כל העיר ירושלים</td>\n",
       "      <td>https://www.kolhair.co.il/digital-edition/</td>\n",
       "      <td>dRUjB3pqPv09pCdNCc+N5A==</td>\n",
       "      <td>1605208329563089</td>\n",
       "      <td>2020-11-12 19:12:09.563089</td>\n",
       "      <td>www.kolhair.co.il</td>\n",
       "      <td>digital-edition/</td>\n",
       "      <td>digital-edition/ מהדורה-דיגיטלית | כל העיר ירו...</td>\n",
       "      <td>digital edition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20953</th>\n",
       "      <td>NaN</td>\n",
       "      <td>LINK</td>\n",
       "      <td>מהדורה-דיגיטלית | כל העיר ירושלים</td>\n",
       "      <td>https://www.kolhair.co.il/digital-edition/#</td>\n",
       "      <td>dRUjB3pqPv09pCdNCc+N5A==</td>\n",
       "      <td>1605208321008995</td>\n",
       "      <td>2020-11-12 19:12:01.008995</td>\n",
       "      <td>www.kolhair.co.il</td>\n",
       "      <td>digital-edition/#</td>\n",
       "      <td>digital-edition/# מהדורה-דיגיטלית | כל העיר יר...</td>\n",
       "      <td>digital edition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20954</th>\n",
       "      <td>NaN</td>\n",
       "      <td>LINK</td>\n",
       "      <td>מהדורה-דיגיטלית | כל העיר ירושלים</td>\n",
       "      <td>https://www.kolhair.co.il/digital-edition/</td>\n",
       "      <td>dRUjB3pqPv09pCdNCc+N5A==</td>\n",
       "      <td>1605208309849376</td>\n",
       "      <td>2020-11-12 19:11:49.849376</td>\n",
       "      <td>www.kolhair.co.il</td>\n",
       "      <td>digital-edition/</td>\n",
       "      <td>digital-edition/ מהדורה-דיגיטלית | כל העיר ירו...</td>\n",
       "      <td>digital edition</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20955 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             favicon_url page_transition  \\\n",
       "0      https://www.thepythoncode.com/static/img/pytho...            LINK   \n",
       "1                     https://www.google.com/favicon.ico            LINK   \n",
       "2                                                    NaN            LINK   \n",
       "3                     https://www.google.com/favicon.ico       GENERATED   \n",
       "4                     https://www.google.com/favicon.ico       GENERATED   \n",
       "...                                                  ...             ...   \n",
       "20950                                                NaN            LINK   \n",
       "20951                                                NaN          RELOAD   \n",
       "20952                                                NaN            LINK   \n",
       "20953                                                NaN            LINK   \n",
       "20954                                                NaN            LINK   \n",
       "\n",
       "                                                   title  \\\n",
       "0             How to Read Emails in Python - Python Code   \n",
       "1                                         Google Takeout   \n",
       "2                                         Google Takeout   \n",
       "3                        google takeout - חיפוש ב-Google   \n",
       "4      python get latest emails in inbox - חיפוש ב-Go...   \n",
       "...                                                  ...   \n",
       "20950           LinkedIn Profile Scraper | Phantombuster   \n",
       "20951                                  Registration page   \n",
       "20952                  מהדורה-דיגיטלית | כל העיר ירושלים   \n",
       "20953                  מהדורה-דיגיטלית | כל העיר ירושלים   \n",
       "20954                  מהדורה-דיגיטלית | כל העיר ירושלים   \n",
       "\n",
       "                                                     url  \\\n",
       "0      https://www.thepythoncode.com/article/reading-...   \n",
       "1      https://takeout.google.com/settings/takeout?pli=1   \n",
       "2      https://takeout.google.com/settings/takeout?pli=1   \n",
       "3      https://www.google.com/search?q=google+takeout...   \n",
       "4      https://www.google.com/search?q=python+get+lat...   \n",
       "...                                                  ...   \n",
       "20950  https://phantombuster.com/automations/linkedin...   \n",
       "20951  https://trailer.web-view.net/LandingPagesResul...   \n",
       "20952         https://www.kolhair.co.il/digital-edition/   \n",
       "20953        https://www.kolhair.co.il/digital-edition/#   \n",
       "20954         https://www.kolhair.co.il/digital-edition/   \n",
       "\n",
       "                      client_id         time_usec                       time  \\\n",
       "0      ChCEMzICD0Hcp6qr+O44Tw==  1636729058732261 2021-11-12 14:57:38.732261   \n",
       "1      ChCEMzICD0Hcp6qr+O44Tw==  1636729053479999 2021-11-12 14:57:33.479999   \n",
       "2      ChCEMzICD0Hcp6qr+O44Tw==  1636729051496083 2021-11-12 14:57:31.496083   \n",
       "3      ChCEMzICD0Hcp6qr+O44Tw==  1636729048837442 2021-11-12 14:57:28.837442   \n",
       "4      ChCEMzICD0Hcp6qr+O44Tw==  1636729042414008 2021-11-12 14:57:22.414008   \n",
       "...                         ...               ...                        ...   \n",
       "20950  dRUjB3pqPv09pCdNCc+N5A==  1605253150283348 2020-11-13 07:39:10.283348   \n",
       "20951  dRUjB3pqPv09pCdNCc+N5A==  1605252110781953 2020-11-13 07:21:50.781953   \n",
       "20952  dRUjB3pqPv09pCdNCc+N5A==  1605208329563089 2020-11-12 19:12:09.563089   \n",
       "20953  dRUjB3pqPv09pCdNCc+N5A==  1605208321008995 2020-11-12 19:12:01.008995   \n",
       "20954  dRUjB3pqPv09pCdNCc+N5A==  1605208309849376 2020-11-12 19:11:49.849376   \n",
       "\n",
       "                     website  \\\n",
       "0      www.thepythoncode.com   \n",
       "1         takeout.google.com   \n",
       "2         takeout.google.com   \n",
       "3             www.google.com   \n",
       "4             www.google.com   \n",
       "...                      ...   \n",
       "20950      phantombuster.com   \n",
       "20951   trailer.web-view.net   \n",
       "20952      www.kolhair.co.il   \n",
       "20953      www.kolhair.co.il   \n",
       "20954      www.kolhair.co.il   \n",
       "\n",
       "                                                 new_url  \\\n",
       "0                       article/reading-emails-in-python   \n",
       "1                                 settings/takeout?pli=1   \n",
       "2                                 settings/takeout?pli=1   \n",
       "3      search?q=google+takeout&oq=google+takeout&aqs=...   \n",
       "4      search?q=python+get+latest+mails+in+inbox&oq=p...   \n",
       "...                                                  ...   \n",
       "20950  automations/linkedin/3112/linkedin-profile-scr...   \n",
       "20951  LandingPagesResult.aspx?_p=f3f2a2&_u=333waaac&...   \n",
       "20952                                   digital-edition/   \n",
       "20953                                  digital-edition/#   \n",
       "20954                                   digital-edition/   \n",
       "\n",
       "                                               full_data  \\\n",
       "0      article/reading-emails-in-python how to read e...   \n",
       "1                 settings/takeout?pli=1 google takeout    \n",
       "2                 settings/takeout?pli=1 google takeout    \n",
       "3      search?q=google+takeout&oq=google+takeout&aqs=...   \n",
       "4      search?q=python+get+latest+mails+in+inbox&oq=p...   \n",
       "...                                                  ...   \n",
       "20950  automations/linkedin/3112/linkedin-profile-scr...   \n",
       "20951  landingpagesresult.aspx?_p=f3f2a2&_u=333waaac&...   \n",
       "20952  digital-edition/ מהדורה-דיגיטלית | כל העיר ירו...   \n",
       "20953  digital-edition/# מהדורה-דיגיטלית | כל העיר יר...   \n",
       "20954  digital-edition/ מהדורה-דיגיטלית | כל העיר ירו...   \n",
       "\n",
       "                                         clean_full_data  \n",
       "0      article reading emails in python how to read e...  \n",
       "1                 settings takeout pli 1 google takeout   \n",
       "2                 settings takeout pli 1 google takeout   \n",
       "3      search q google takeout oq google takeout aqs ...  \n",
       "4      search q python get latest mails in inbox oq p...  \n",
       "...                                                  ...  \n",
       "20950  automations linkedin 3112 linkedin profile scr...  \n",
       "20951  landingpagesresult aspx p f3f2a2 u 333waaac c ...  \n",
       "20952                                   digital edition   \n",
       "20953                                   digital edition   \n",
       "20954                                   digital edition   \n",
       "\n",
       "[20955 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## tags analysis\n",
    "new_tags_ls=set(tags['Attribute:TagName'].tolist()) - set(word_list)\n",
    "dictionary_tags_ls=set(tags['Attribute:TagName'].tolist()) & set(word_list)\n",
    "# bring back top 100\n",
    "top_100=tags[tags['Attribute:TagName'].isin(dictionary_tags_ls)].loc[:100]\n",
    "new_tags=tags[tags['Attribute:TagName'].isin(new_tags_ls)]\n",
    "new_tags=pd.concat([new_tags,top_100])\n",
    "new_tags=new_tags.sort_values(\"rank\")\n",
    "# clean tags\n",
    "new_tags['clean_tags']=new_tags['Attribute:TagName'].replace(\"-\",\" \",regex=True)\n",
    "history['full_data'] = (history['new_url']+\" \"+history['title']+\" \").str.lower()\n",
    "# delete non-aplha numeric\n",
    "history['clean_full_data']=history['full_data'].str.replace(r'[^A-Za-z0-9 ]+', ' ')\n",
    "# delete multiple spaces\n",
    "history['clean_full_data'] = history['clean_full_data'].replace('\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take few Mintues\n",
    "ls_tag_in=filter_tags((r\" \"+(new_tags['clean_tags'])+r\" \").tolist(),history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_tags_in=pd.Series(ls_tag_in)\n",
    "ser_tags_in=ser_tags_in[ser_tags_in.str.len()>5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_tags_in.drop_duplicates().to_excel(r\"C:\\Users\\meira\\tovtech\\tags_in.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# genrete report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "import plotly.express as px\n",
    "import cufflinks as cf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "cf.go_offline()\n",
    "time_df = pd.DataFrame(columns=[\"tag\",\"time\"])\n",
    "\n",
    "tag_list = history.columns.tolist()[13:-2]\n",
    "time_df['tag'] = tag_list\n",
    "time_list = []\n",
    "\n",
    "for tag in tag_list:\n",
    "    tag_time = (history.loc[history[tag] == 1, 'time_spent'].sum())\n",
    "    time_list.append(tag_time)\n",
    "\n",
    "time_df['time'] = time_list\n",
    "time_df.sort_values('time', ascending=False, inplace=True)\n",
    "time_df.reset_index(drop=True, inplace=True)\n",
    "time_df.loc[10:, \"tag\"] = \"Other topic\"\n",
    "fig = px.pie(time_df, values='time', names='tag', title='Time spent on topic')\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
